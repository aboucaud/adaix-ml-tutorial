<!DOCTYPE html>
<html lang="en">
<!-- <html class="dark-blue-theme"> -->
<head>
  <meta charset="utf-8">
  <title>Hands on Neural Networks</title>
  <meta name="author" content="Alexandre Boucaud">
  <meta name="description" content="ADAIX Machine Learning course">
  <link rel="stylesheet" type="text/css" href="../css/slides.css">
</head>
<body>
  <textarea id="source">
class: center, middle

# Hands on Neural Networks

Emille Ishida - Alexandre Boucaud

---

## Foreword

The following slides provide examples of neural network models written in Python, using the [Keras][keras] library. Keras provides a high level API to create models and to run them with numerical tensor libraries (_backends_) such as [TensorFlow][tf], [CNTK][cntk] or [Theano][theano].

All presented models work with Keras version 2.X.

[keras]: https://keras.io/
[tf]: https://www.tensorflow.org/
[cntk]: https://docs.microsoft.com/fr-fr/cognitive-toolkit/
[theano]: http://www.deeplearning.net/software/theano/

---

## Outline

- Neurons - Layers - MLP
- Activation functions
- Backpropagation - forward vs. backward pass
- Optimization - learning rate
- Convolutional Layers
- Pooling, Dropout
- Tour of deep neural nets


---

## Neurons


---

## class: center, middle

# Hands on Neural Networks

Emille Ishida - Alexandre Boucaud

---

## Foreword

The following slides provide examples of neural network models written in Python, using the [Keras][keras] library. Keras provides a high level API to create models and to run them with numerical tensor libraries (_backends_) such as [TensorFlow][tf], [CNTK][cntk] or [Theano][theano].

All presented models work with Keras version 2.X.

[keras]: https://keras.io/
[tf]: https://www.tensorflow.org/
[cntk]: https://docs.microsoft.com/fr-fr/cognitive-toolkit/
[theano]: http://www.deeplearning.net/software/theano/

---

## Outline

- Neurons - Layers - MLP
- Activation functions
- Backpropagation - forward vs. backward pass
- Optimization - learning rate
- Convolutional Layers
- Pooling, Dropout
- Tour of deep neural nets


---

## Neurons


---
## Anatomy of a neural net

.center[<img src="img/mlp_annotated.jpeg", width="600px;" />]

---
## Multi-layer perceptron (MLP)

.center[<img src="img/mlp.jpeg", width="600px;" />]

---
## Multi-layer perceptron (MLP)

```python
from keras.models import Sequential
from keras.layers import Dense

# initialize model
model = Sequential()

# add layers
model.add(Dense(4, input_dim=3))
model.add(Dense(4))
model.add(Dense(1))
```

--

```python
# print model structure
model.summary()
```

--

```
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
dense_1 (Dense)              (None, 4)                 16
_________________________________________________________________
dense_2 (Dense)              (None, 4)                 20
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 5
=================================================================
Total params: 41
Trainable params: 41
Non-trainable params: 0
_________________________________________________________________
```

---

## Activation functions



---

## Activation functions

```python

```

---

## Convolutional nets

.center[<img src="img/convolution_gifs/same_padding_no_strides.gif"/>]
.credits[[arXiv:1603.07285](https://arxiv.org/abs/1603.07285)]

---

## Convolutional nets - strides

.left-column[<img src="img/convolution_gifs/same_padding_no_strides.gif" />]
.right-column[<img src="img/convolution_gifs/padding_strides.gif" />]
.credits[[arXiv:1603.07285](https://arxiv.org/abs/1603.07285)]

---
## Convolutional nets - strides 

.left-column[
```python
from keras.model import Sequential
from keras.layers import Conv2D

model = Sequential()
model.add(Conv2D(1, (3, 3), 
                 strides=1, 
                 padding='same', 
                 input_shape=(5, 5, 1)))
model.summary()
```

```
_________________________________________
Layer (type)            Output Shape     
=========================================
conv2d (Conv2D)         (None, 5, 5, 1)  
=========================================
Total params: 10
Trainable params: 10
Non-trainable params: 0
_________________________________________
```
] 
.right-column[
<img src="img/convolution_gifs/same_padding_no_strides.gif" />
] 

---
## Convolutional nets - strides

.left-column[
```python
from keras.model import Sequential
from keras.layers import Conv2D

model = Sequential()
model.add(Conv2D(1, (3, 3), 
*                strides=2, 
                 padding='same', 
                 input_shape=(5, 5, 1)))
model.summary()
```

```
_________________________________________
Layer (type)            Output Shape     
=========================================
conv2d (Conv2D)         (None, 3, 3, 1)  
=========================================
Total params: 10
Trainable params: 10
Non-trainable params: 0
_________________________________________
```
]
.right-column[ 
<img src="img/convolution_gifs/padding_strides.gif" />
]
 
---
class: center, middle
# Optimization


---
## Overfitting

---
## Learning rate

---
## Dropout

a % of random neurons are .grey[switched off] during training  
it mimics different architectures being trained at each step 

.center[<img src="img/dropout.png" width="600 px;" />]
.credits[Hinton +12]

---
## Batch normalization

```python
from keras.layers import BatchNormalization

model.add(BatchNormalization())

```

---
## what we did not talk about

- weight initialization
- gradient clipping
- regularization

---
class: center, middle

# In practice

---
## Learning history - loss

.left-column[
```python
import matplotlib.pyplot as plt

# ...
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val))

# Visualizing the training                    
plt.plot(history.history['loss'],
         label='train')
plt.plot(history.history['val_loss'],
         label='validation')
plt.legend()
plt.xlabel('epochs')
plt.ylabel('loss')


```
]
.right-column[ 
<img src="img/history.png">
]

---
## Learning history - accuracy


---
## Callbacks


---




  </textarea>
  <style TYPE="text/css">
    code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}
  </style>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'] // removed 'code' entry
    }
    });
    MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
           all[i].SourceElement().parentNode.className += ' has-jax';
           }
           });
           </script>
  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <script type="text/javascript" src="../remark-latest.min.js"></script>
  <script type="text/javascript">
    var slideshow = remark.create({
      // sourceUrl: 'slides.md',
      // Set the slideshow display ratio
      // Default: '4:3'
      // Alternatives: '16:9', ...
      ratio: '4:3',
      // Navigation options
      navigation: {
        // Enable or disable navigating using scroll
        scroll: false,
        // Enable or disable navigation using touch
        touch: true,
        // Enable or disable navigation using click
        click: false,
      },
      // Customize slide number label, either using a format string..
      // slideNumberFormat: 'Slide %current% of %total%',
      // .. or by using a format function
      // slideNumberFormat: function (current, total) {
        // return 'Slide ' + current + ' of ' + total;
      // },
      slideNumberFormat: '%current%',
      // Enable or disable counting of incremental slides in the slide counting
      // countIncrementalSlides: true,
      // https://github.com/gnab/remark/wiki/Configuration#highlighting
      // highlightLanguage: 'python',
      //arta, ascetic, dark, default, far, github, googlecode, idea, ir-black, magula, monokai, rainbow, solarized-dark, solarized-light, sunburst, tomorrow, tomorrow-night-blue, tomorrow-night-bright, tomorrow-night, tomorrow-night-eighties, vs, zenburn
      highlightStyle: 'zenburn',
      // highlightStyle: 'tomorrow-night',
      highlightLines: true,
      highlightSpans: true,
      });
  </script>
</body>
</html>
